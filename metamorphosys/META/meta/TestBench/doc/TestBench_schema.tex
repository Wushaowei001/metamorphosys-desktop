
\documentclass{article}
\usepackage{graphicx}
\usepackage{outlines}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{nameref}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{listings}
\usepackage[margin=1in]{geometry}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\hypersetup{%
	pdfborder = {0 0 0}
}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
  {-3.25ex\@plus -1ex \@minus -.2ex}%
  {1.5ex \@plus .2ex}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{5}{\z@}%
  {-3.25ex\@plus -1ex \@minus -.2ex}%
  {1.5ex \@plus .2ex}%
  {\normalfont\normalsize\bfseries}}
\makeatother

\begin{document}

\title{META Test Bench Manifest Specification Documentation\\Version 1, Draft 1}
\author{Adam Nagel\\
	Institute for Software Integrated Systems (ISIS)\\
	Vanderbilt University\\
	\texttt{adam@isis.vanderbilt.edu}\\
	\\
	Developed for the DARPA Adaptive Vehicle Make (AVM) Program}
\date{\today}

\maketitle

\begin{center}
\includegraphics[scale=0.75]{ISIS-logoNEW} \hspace{1cm} \includegraphics[scale=0.103]{DARPA-logo}
\end{center}

\tableofcontents

\section{Overview}

\subsection{10,000 ft View}
The Test Bench Manifest is the central part of every META test bench. It captures several key pieces of information:

\begin{itemize}
\item The Parameters of the Test Bench
\item The Metrics to be calculated by the end of Test Bench execution
\item The Artifacts generated and used during the Test Bench execution
\item The steps for executing the Test Bench
\end{itemize}

The initial manifest file, along with supporting artifacts, is generated by the META tools.

A \textbf{test bench executor} uses the file to run the steps required for execution. The executor must go through each of the Steps defined, in order, one-by-one. For each, it must run the pre-processing script, execute the main Invocation statement, then run the post-processing script. Pre- and post-processing scripts may read from, and modify, the manifest file itself. This can be useful for reading Parameters, writing Metrics, and altering the Parameters of other invocation Steps.

\subsection{Sample Use Case (Conceptual)}
Let's say that a Test Bench is designed to support a manufacturability and costing analysis.

\begin{enumerate}
\item The META tools generate:
	\begin{itemize}
	\item Design Model export
	\item Component Model exports
	\item Manufacturing Models for each Component
	\item A Manifest file cross-indexing each component instance with its manufacturing model
	\item An XML file describing how the individual Component CAD Models should be composed to form a system model
	\item a \textbf{testbench\_manifest.json} file indexing:
		\begin{itemize}
		\item All above items as Artifacts, with key elements also including Tags
		\item Metrics
			\begin{itemize}
			\item Cost
			\item Manufacturing Time
			\end{itemize}
		\item Steps (for execution)
			\begin{itemize}
			\item Assemble the System CAD model
			\item Run the manufacturability analysis
			\end{itemize}
		\end{itemize}
	\end{itemize}
\item A \textbf{test bench executor} loads the \textbf{testbench\_manifest.json} file, and iterates over the steps. 
	\begin{itemize}
	\item Step 1: Assemble the system CAD model
		\begin{itemize}
		\item Pre-Processing: none
		\item Invocation: Run the BAT file that assembles the system model
		\item Post-Processing:
			\begin{itemize}
			\item Add the "cadmetrics.xml" file to the \textbf{testbench\_manifest.json} Artifacts list
			\item Add the generated system CAD model as an Artifact with a tag of "System Model"
			\item Add the other generated CAD models to the \textbf{testbench\_manifest.json} Artifacts list
			\end{itemize}
		\end{itemize}
	\item Step 2: Perform the manufacturability analysis
		\begin{itemize}
		\item Pre-Processing:
			\begin{itemize}
			\item Build an index file for the manufacturability analysis
			\item Add the above index file to the \textbf{testbench\_manifest.json} Artifacts list
			\item Upload all artifacts to a storage system used by the manufacturability analysis
			\item Use the server's response, with package ID, to alter the XXXX Parameter of the Invocation section of this step.
			\item Generate the post-processing script to be used as part of this step, embedding the package ID so that it knows what results to poll for
			\end{itemize}
		\item Invocation: Invoke the manufacturability via a REST interface
		\item Post-Processing:
			\begin{itemize}
			\item Poll the manufacturability service, using the package ID (discovered during the preprocessing step), until a response is ready
			\item Use the results to populate the Metrics of \textbf{testbench\_manifest.json}
			\end{itemize}
		\end{itemize}
	\item Step 3: Clean up the Test Bench
		\begin{itemize}
		\item Pre-Processing: none
		\item Invocation: Python script to delete all unnecessary Artifacts from disk and \textbf{testbench\_manifest.json}
		\item Post-Processing: none
		\end{itemize}
	\end{itemize}
\item The resulting package is passed to the META Dashboard to support visualization and comparison of designs
\end{enumerate}

%\section{Core Concepts}

%\section{Implementation}

\section{Classes}
\subsection{TestBenchManifest}
This is the root object of a \textbf{testbench\_manifest.json} document.
\subsection{Parameter}
This parameter is defined in the META test bench model. Analysis tools that run during test bench execution may use these values to parameterize execution. If the test bench is being used in a PCC or PET analysis, then this parameter may be varied for each run by the PCC or PET execution tool.
\subsection{Metric}
This captures a value that is exepected to be provided after test bench execution. It will be passed to the META Dashboard as the result for a specific test bench, evaluated against a specific design. Before test bench execution is completed, values must be provided for these. If the test bench is being used in a PCC or PET analysis, this is fed back to the experiment driver/optimizer.
%\subsection{Step}
\subsection{Artifact}
This allows an explicit pointer to an artifact expected by any tool in the analysis chain. The "tag" field will indicate a key artifact type, such as "Component Model Index" or "Design Model". Tools that operate on the test bench should search the Artifact list by "tag" in order to find the key artifacts needed for execution. Each artifact's "Tag" value must be unique.

\section{Appendix}
\subsection{Sample Manifest File}

\lstinputlisting
[breaklines=true,tabsize=1,showspaces=false,showstringspaces=false,language=Java,basicstyle=\ttfamily\scriptsize]
{../exampleprojects/python/exampleManifest.json}

\subsection{Sample Manifest Generation Code}

\lstinputlisting
[breaklines=true,tabsize=1,showspaces=false,showstringspaces=false,language=Python,basicstyle=\ttfamily\scriptsize]
{../exampleprojects/python/generateSample.py}

\end{document}